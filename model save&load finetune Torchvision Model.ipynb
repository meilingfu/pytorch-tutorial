{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [3008291748744, 3008291748888, 3008291748960, 3008291749032, 3008291749104, 3008291749176, 3008291749248, 3008291746872, 3008291749320, 3008291749392]}]\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "#initialize model\n",
    "model=TheModelClass()\n",
    "#initialize optimizer\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "#print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor,'\\t',model.state_dict()[param_tensor].size())\n",
    "    \n",
    "#print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name,'\\t',optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.1\n",
      "Torchvision version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets,models,transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch version:\",torch.__version__)\n",
    "print(\"Torchvision version:\",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "\n",
    "data_dir=\"./hymenoptera_data\"\n",
    "#Models to choose from[ResNet,AlexNet,vgg,squeezenet,densenet,inception]\n",
    "model_name=\"squeezenet\"\n",
    "#number of classes in the dataset\n",
    "num_classes=2\n",
    "#batch size for training(change depending on how mang memories you have)\n",
    "batch_size=8\n",
    "#number of epochs to train for\n",
    "num_epochs=15\n",
    "#flags for finetune or feature extract\n",
    "feature_extract=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and validation code\n",
    "#每个epoch后进行一次validation，根据validation准确率追踪最佳模型，每个epoch输出training和validation accuracy\n",
    "def train_model(model,dataloaders,criterion,optimizer,num_epochs=25,is_inception=False):\n",
    "    since=time.time()\n",
    "    val_acc_history=[]\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    best_acc=0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch,num_epochs-1))\n",
    "        print('-'*10)\n",
    "        #each epoch has training and validation phase\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                model.train() #set model to training mode\n",
    "            else:\n",
    "                model.eval() #set model to validation mode\n",
    "            running_loss=0.0\n",
    "            running_corrects=0\n",
    "            #Iterator over data\n",
    "            for inputs,labels in dataloaders[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                #zero the parameter gradient\n",
    "                optimizer.zero_grad()\n",
    "                #forward,如果是训练模式，记录模型\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    #训练时考虑inception网络的附属输出，计算损失函数\n",
    "                    if is_inception and phase=='train':\n",
    "                        outputs,aux_outputs=model(inputs)\n",
    "                        loss1=criterion(outputs,labels)\n",
    "                        loss2=criterion(aux_outputs,labels)\n",
    "                        loss=loss1+0.4*loss2\n",
    "                    else:\n",
    "                        outputs=model(inputs)\n",
    "                        loss=criterion(outputs,labels)\n",
    "                    #预测的类别\n",
    "                    _,preds=torch.max(outputs,1)\n",
    "                    #训练：反向传播和更新参数\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()      \n",
    "                #statistics\n",
    "                running_loss+=loss.item()*inputs.size(0)\n",
    "                running_corrects+=torch.sum(preds==labels.data)\n",
    "            epoch_loss=running_loss/len(dataloaders[phase].dataset)\n",
    "            epoch_acc=running_corrects.double()/len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "            #deep copy the model\n",
    "            if phase=='val' and epoch_acc>best_acc:\n",
    "                best_model_wts=copy.deepcopy(model.state_dict())\n",
    "                best_acc=epoch_acc\n",
    "            if phase=='val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "    time_elapsed=time.time()-since\n",
    "    print('Train completed in {:.0f}m {:.0f}s'.format(time_elapsed//60,time_elapsed%60))\n",
    "    print('Best validation accuracy: {:.4f}'.format(best_acc))\n",
    "    #load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set model parametes'requires_grad attribute\n",
    "#默认加载的预训练模型requires_grad属性为True\n",
    "def set_parameters_requires_grad(model,feature_extraction):\n",
    "    if feature_extraction:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13051\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\13051\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#CNN模型的最后一层通常是FC层，neural节点数目是数据集中的类别数目\n",
    "#initialize and reshape the network，修改网络最后一层\n",
    "def initialize_model(model_name,num_classes,feature_extract,use_pretrained=True):\n",
    "    model_ft=None\n",
    "    input_size=0   #输入图片的尺寸\n",
    "    \n",
    "    if model_name=='resnet':\n",
    "        model_ft=models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameters_requires_grad(model_ft,feature_extract)\n",
    "        num_ftrs=model_ft.fc.in_features\n",
    "        #重新定义最后一层全连接层\n",
    "        model_ft.fc=nn.Linear(num_ftrs,num_classes)\n",
    "        input_size=224\n",
    "    elif model_name=='alexnet':\n",
    "        model_ft=models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameters_requires_grad(model_ft,feature_extract)\n",
    "        num_ftrs=model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6]=nn.Linear(num_ftrs,num_classes)\n",
    "        input_size=224\n",
    "    elif model_name=='vgg':\n",
    "        model_ft=models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameters_features_grad(model_ft,feature_extract)\n",
    "        num_ftrs=model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6]=nn.Linear(num_ftrs,num_classes)\n",
    "        input_size=224\n",
    "    elif model_name=='squeezenet':\n",
    "        model_ft=models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameters_requires_grad(model_ft,feature_extract)\n",
    "        model_ft.classifier[1]=nn.Conv2d(512,num_classes,kernel_size=(1,1),stride=(1,1))\n",
    "        model_ft.num_classes=num_classes\n",
    "        input_size=224\n",
    "    elif model_name=='densenet':\n",
    "        model_ft=models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameters_requires_grad(model_ft,feature_extract)\n",
    "        num_ftrs=model_ft.classifier.in_features\n",
    "        model_ft.classifier=nn.Linear(num_ftrs,num_classes)\n",
    "        input_size=224\n",
    "    elif model_name=='inception':\n",
    "        model_ft=models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameters_requires_grad(model_ft,feature_extract)\n",
    "        #handle the auxilary net\n",
    "        num_ftrs=model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc=nn.Linear(num_ftrs,num_classes)\n",
    "        #hadle the primary net\n",
    "        num_ftrs=model_ft.fc.in_features\n",
    "        model_ft.fc=nn.Linear(num_ftrs,num_classes)\n",
    "        input_size=299\n",
    "    else:\n",
    "        print('Invalid model name.Exit...')\n",
    "        exit()\n",
    "    return model_ft,input_size\n",
    "#initialize model for this run\n",
    "model_ft,input_size=initialize_model(model_name,num_classes,feature_extract,use_pretrained=True)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing datasets and dataloaders....\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation and normalization for training\n",
    "data_transforms={\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val':transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])}\n",
    "print('Initializing datasets and dataloaders....')\n",
    "#create training and validation dataset\n",
    "image_datasets={x:datasets.ImageFolder(os.path.join(data_dir,x),data_transforms[x]) for x in ['train','val']}\n",
    "#create training and validation dataloader\n",
    "dataloaders_dict={x:torch.utils.data.DataLoader(image_datasets[x],batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "                      for x in ['train','val']}\n",
    "#detect if we have a GPU available\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "#send the model to GPU\n",
    "model_ft=model_ft.to(device)\n",
    "#将需要优化更新的参数聚集到一起，finetuning所有参数都要更新，feature extract只更新最后一层参数\n",
    "params_to_update=model_ft.parameters()\n",
    "print('Params to learn:')\n",
    "if feature_extract:\n",
    "    params_to_update=[]\n",
    "    for name,params in model_ft.named_parameters():\n",
    "        if params.requires_grad==True:\n",
    "            params_to_update.append(params)\n",
    "            print('\\t',name)\n",
    "else:\n",
    "    for name,params in model_ft.named_parameters():\n",
    "        if params.requires_grad==True:\n",
    "            print('\\t',name)\n",
    "#定义优化函数\n",
    "optimizer=optim.SGD(params_to_update,lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.5952 Acc: 0.7254\n",
      "val Loss: 0.3562 Acc: 0.8758\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.2845 Acc: 0.8607\n",
      "val Loss: 0.3288 Acc: 0.9216\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.2134 Acc: 0.9221\n",
      "val Loss: 0.3294 Acc: 0.9216\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.2487 Acc: 0.8811\n",
      "val Loss: 0.2875 Acc: 0.9216\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.1905 Acc: 0.9098\n",
      "val Loss: 0.3128 Acc: 0.9216\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9508\n",
      "val Loss: 0.3168 Acc: 0.9150\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.9139\n",
      "val Loss: 0.3118 Acc: 0.9150\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1691 Acc: 0.9221\n",
      "val Loss: 0.3085 Acc: 0.9346\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.9221\n",
      "val Loss: 0.3287 Acc: 0.9281\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9344\n",
      "val Loss: 0.3226 Acc: 0.9216\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1144 Acc: 0.9508\n",
      "val Loss: 0.3364 Acc: 0.9216\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9549\n",
      "val Loss: 0.3871 Acc: 0.8889\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9426\n",
      "val Loss: 0.3977 Acc: 0.9346\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1711 Acc: 0.9385\n",
      "val Loss: 0.3775 Acc: 0.9346\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9549\n",
      "val Loss: 0.3754 Acc: 0.9216\n",
      "\n",
      "Train completed in 2m 15s\n",
      "Best validation accuracy: 0.9346\n"
     ]
    }
   ],
   "source": [
    "#Run training and validation step\n",
    "#Setup the loss function\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "#training and evaluation\n",
    "model_ft,hist=train_model(model_ft,dataloaders_dict,criterion,optimizer,num_epochs=num_epochs,is_inception=(model_name=='inception'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13051\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "C:\\Users\\13051\\Anaconda3\\lib\\site-packages\\torchvision\\models\\squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6907 Acc: 0.5205\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6934 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5000\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5000\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.6930 Acc: 0.5082\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.6930 Acc: 0.5041\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.5000\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.6925 Acc: 0.5123\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.6900 Acc: 0.5082\n",
      "val Loss: 0.6995 Acc: 0.4575\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.6898 Acc: 0.4918\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5328\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.6932 Acc: 0.4877\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.6931 Acc: 0.5328\n",
      "val Loss: 0.6931 Acc: 0.4575\n",
      "\n",
      "Train completed in 2m 31s\n",
      "Best validation accuracy: 0.4575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison with model trained from scratch\n",
    "scratch_model,_=initialize_model(model_name,num_classes,feature_extract=False,use_pretrained=False)\n",
    "scratch_model=scratch_model.to(device)\n",
    "scratch_criterion=nn.CrossEntropyLoss()\n",
    "scratch_optimizer=optim.SGD(scratch_model.parameters(),lr=0.001,momentum=0.9)\n",
    "_,scratch_hist=train_model(scratch_model,dataloaders_dict,scratch_criterion,scratch_optimizer,\n",
    "                           num_epochs=num_epochs,is_inception=(model_name=='inception'))\n",
    "#绘制validation accuracy随epoch的曲线\n",
    "ohist=[]\n",
    "shist=[]\n",
    "ohist=[h.cpu().numpy() for h in hist]\n",
    "shist=[h.cpu().numpy() for h in scratch_hist]\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1,num_epochs+1,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
